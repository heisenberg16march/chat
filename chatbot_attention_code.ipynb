{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec1a091-21ed-4c0d-b531-4f5c389a0449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports from libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5c7c9e-4c6e-49d5-9e4d-c9e5cf28f2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ef2a12-c487-4f18-a7d8-7651fdcc91fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bba0b35-6596-46c9-bc04-fa2cd778c77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5d3417-3ca8-457a-9c29-01dba783a2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3512 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  I'm going through some things with my feelings...   \n",
       "1  I'm going through some things with my feelings...   \n",
       "2  I'm going through some things with my feelings...   \n",
       "3  I'm going through some things with my feelings...   \n",
       "4  I'm going through some things with my feelings...   \n",
       "\n",
       "                                            Response  \n",
       "0  If everyone thinks you're worthless, then mayb...  \n",
       "1  Hello, and thank you for your question and see...  \n",
       "2  First thing I'd suggest is getting the sleep y...  \n",
       "3  Therapy is essential for those that are feelin...  \n",
       "4  I first want to let you know that you are not ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading\n",
    "nRowsRead = None # specify 'None' if want to read whole file\n",
    "data_train = pd.read_csv('train.csv', delimiter=',', nrows = nRowsRead)\n",
    "data_train.dataframeName = 'train.csv'\n",
    "nRow, nCol = data_train.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "select_data_train = data_train[['Context', 'Response']]\n",
    "select_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff5e627-8c9b-4880-b536-de87bfeb8261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Context: 0\n",
      "Missing values in Response: 4\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_train)\n",
    "# Check for missing values in 'Context' and 'Response' columns\n",
    "missing_context = df['Context'].isnull().sum()\n",
    "missing_response = df['Response'].isnull().sum()\n",
    "\n",
    "print(f'Missing values in Context: {missing_context}')\n",
    "print(f'Missing values in Response: {missing_response}')\n",
    "\n",
    "# Drop rows with missing 'Context' or 'Response'\n",
    "df.dropna(subset=['Context', 'Response'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c153f0-2c68-4a5e-91ce-a862e51d8bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lemmatised questions: 3508\n",
      "Number of lemmatised answers: 3508\n"
     ]
    }
   ],
   "source": [
    "#Lemmatisation\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_questions = []\n",
    "lemmatized_answers = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Context']) or pd.isnull(row['Response']):\n",
    "        continue\n",
    "        \n",
    "    # Tokenize and lemmatise question\n",
    "    question_tokens = word_tokenize(row['Context'].lower())\n",
    "    question_tokens = [word for word in question_tokens if word not in stop_words]\n",
    "    lemmatized_question = [lemmatizer.lemmatize(word) for word in question_tokens]\n",
    "    \n",
    "    # Tokenize and lemmatise answer\n",
    "    answer_tokens = word_tokenize(row['Response'].lower())\n",
    "    answer_tokens = [word for word in answer_tokens if word not in stop_words]\n",
    "    lemmatized_answer = [lemmatizer.lemmatize(word) for word in answer_tokens]\n",
    "    \n",
    "    # Append lemmatised question and answer to lists\n",
    "    lemmatized_questions.append(lemmatized_question)\n",
    "    lemmatized_answers.append(lemmatized_answer)\n",
    "\n",
    "# Print lengths of lemmatised questions and answers\n",
    "print(\"Number of lemmatised questions:\", len(lemmatized_questions))\n",
    "print(\"Number of lemmatised answers:\", len(lemmatized_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16afabe5-546c-441d-9aec-04943c06e11c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of context_seq: (3508, 244)\n",
      "Shape of response_seq: (3508, 466)\n",
      "Shape of context_seq (sliced for input): (3508, 243)\n",
      "Shape of response_seq (sliced for output): (3508, 465)\n",
      "Shape of attention out: (None, None, 256)\n",
      "Shape of decoder_outputs: (None, None, 3256)\n",
      "Shape of encoder_outputs: (None, None, 256)\n",
      "Shape of decoder_concat_input: (None, None, 512)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">416,768</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">416,768</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ not_equal_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,670,328</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3256</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m416,768\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m416,768\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ not_equal_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,670,328\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m3256\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,292,344</span> (12.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,292,344\u001b[0m (12.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,292,344</span> (12.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,292,344\u001b[0m (12.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_9_1/attention_4_1/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_29536\\792910659.py\", line 84, in <module>\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 329, in fit\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 122, in one_step_on_iterator\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 57, in train_step\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 826, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 199, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 151, in _run_through_graph\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 583, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 826, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\attention\\attention.py\", line 227, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\attention\\attention.py\", line 175, in _apply_scores\n\nIncompatible shapes: [64,465,466] vs. [64,466]\n\t [[{{node functional_9_1/attention_4_1/sub}}]] [Op:__inference_one_step_on_iterator_15422]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Train the model (assuming you have train_context and train_response after preprocessing)\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([context_seq, response_seq[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], response_seq[:,\u001b[38;5;241m1\u001b[39m:], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# After training, the model for inference\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Define encoder model\u001b[39;00m\n\u001b[0;32m     88\u001b[0m encoder_model \u001b[38;5;241m=\u001b[39m Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_9_1/attention_4_1/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_29536\\792910659.py\", line 84, in <module>\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 329, in fit\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 122, in one_step_on_iterator\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 57, in train_step\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 826, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 199, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 151, in _run_through_graph\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 583, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 826, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\attention\\attention.py\", line 227, in call\n\n  File \"C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\attention\\attention.py\", line 175, in _apply_scores\n\nIncompatible shapes: [64,465,466] vs. [64,466]\n\t [[{{node functional_9_1/attention_4_1/sub}}]] [Op:__inference_one_step_on_iterator_15422]"
     ]
    }
   ],
   "source": [
    "# Tokenize input and output sequences\n",
    "context_tokenizer = Tokenizer()\n",
    "context_tokenizer.fit_on_texts(lemmatized_questions)\n",
    "context_seq = context_tokenizer.texts_to_sequences(lemmatized_questions)\n",
    "context_seq = pad_sequences(context_seq, padding='post')\n",
    "\n",
    "response_tokenizer = Tokenizer()\n",
    "response_tokenizer.fit_on_texts(lemmatized_answers)\n",
    "response_seq = response_tokenizer.texts_to_sequences(lemmatized_answers)\n",
    "response_seq = pad_sequences(response_seq, padding='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of context_seq:\", context_seq.shape)\n",
    "print(\"Shape of response_seq:\", response_seq.shape)\n",
    "print(\"Shape of context_seq (sliced for input):\", context_seq[:,:-1].shape)\n",
    "print(\"Shape of response_seq (sliced for output):\", response_seq[:,1:].shape)\n",
    "\n",
    "max_question_length = max(len(seq) for seq in context_seq)\n",
    "max_response_length = max(len(seq) for seq in response_seq)\n",
    "sequence_length = max(max_question_length, max_response_length)  # Using the maximum found length\n",
    "context_seq = pad_sequences(context_seq, maxlen=sequence_length, padding='post')\n",
    "response_seq = pad_sequences(response_seq, maxlen=sequence_length, padding='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your neural network architecture\n",
    "vocab_size = len(context_tokenizer.word_index) + 1\n",
    "embed_size = 128\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(vocab_size, embed_size, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(vocab_size, embed_size, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Attention mechanism\n",
    "attention_out = Attention()([decoder_outputs, encoder_outputs])\n",
    "print(\"Shape of attention out:\", attention_out.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate attention output and decoder output\n",
    "decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attention_out])\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of decoder_outputs:\", decoder_outputs.shape)\n",
    "print(\"Shape of encoder_outputs:\", encoder_outputs.shape)\n",
    "print(\"Shape of decoder_concat_input:\", decoder_concat_input.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model (assuming you have train_context and train_response after preprocessing)\n",
    "model.fit([context_seq, response_seq[:,:-1]], response_seq[:,1:], batch_size=64, epochs=10, validation_split=0.2)\n",
    "\n",
    "# After training, the model for inference\n",
    "# Define encoder model\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
    "\n",
    "# Define decoder model\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_attention_out, decoder_attention_states = attention_layer([decoder_outputs, encoder_outputs])\n",
    "decoder_concat_out = Concatenate(axis=-1)([decoder_outputs, decoder_attention_out])\n",
    "\n",
    "decoder_states_outputs = [decoder_states, decoder_attention_states]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_concat_out)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states_outputs\n",
    ")\n",
    "\n",
    "# Define functions for inference\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_output, states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = response_tokenizer.word_index['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = response_tokenizer.index_word[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != '<end>':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_token == '<end>' or len(decoded_sentence.split()) > max_response_length):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552b9fd-0bbf-4212-9acd-f7ebf870d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, Attention\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Assuming vocabulary size, embedding size, and latent dimensions are defined\n",
    "vocab_size = 10000  # Adjust based on your tokenizer\n",
    "embed_size = 128\n",
    "latent_dim = 256\n",
    "max_seq_length = 466  # Adjust based on your data\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(vocab_size, embed_size, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(vocab_size, embed_size, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training (Simulated without teacher forcing)\n",
    "# Start with the start-of-sequence token as input and generate each next token\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    for seq_index in range(len(context_seq)):  # Iterate over each sequence\n",
    "        input_seq = context_seq[seq_index:seq_index+1]\n",
    "        target_seq = np.zeros((1, 1))  # Start with start-of-sequence token\n",
    "        target_seq[0, 0] = response_tokenizer.word_index['<sos>']  # Assuming <sos> is your start token\n",
    "        \n",
    "        for i in range(max_seq_length - 1):  # Generate sequence\n",
    "            output_tokens = model.predict([input_seq, target_seq])\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            \n",
    "            if sampled_token_index == response_tokenizer.word_index['<eos>']:  # Assuming <eos> is your end token\n",
    "                break\n",
    "\n",
    "# This simplified loop shows the concept and isn't a full training loop as it doesn't update weights based on error.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
